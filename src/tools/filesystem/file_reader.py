"""æ–‡ä»¶è¯»å–ä¸æœç´¢å·¥å…·ã€‚

æä¾› 5 ç§æ“ä½œï¼Œé€šè¿‡ action å‚æ•°åŒºåˆ†ï¼š
- list_allowed_dirs: åˆ—å‡ºæ‰€æœ‰å¯è®¿é—®çš„ç›®å½•åŠæƒé™
- list_dir: åˆ—å‡ºç›®å½•å†…å®¹ï¼ˆå«æ–‡ä»¶å¤§å°ã€ä¿®æ”¹æ—¶é—´ï¼‰
- find_files: æŒ‰ glob æ¨¡å¼æŸ¥æ‰¾æ–‡ä»¶å
- search_content: åœ¨æ–‡ä»¶å†…å®¹ä¸­æœç´¢æ–‡æœ¬ï¼ˆç±»ä¼¼ grepï¼‰
- read_file: è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆæ”¯æŒåˆ†æ®µè¯»å–ï¼‰

æ‰€æœ‰æ“ä½œéƒ½å— Sandbox æ²™ç®±çº¦æŸï¼Œç¡®ä¿è·¯å¾„å®‰å…¨ã€‚
æ”¯æŒå¤šæ ¹ç›®å½•ç™½åå•ï¼Œè·¯å¾„å¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„ã€ç»å¯¹è·¯å¾„æˆ– ~ è·¯å¾„ã€‚
"""

import os
import re
import time
from pathlib import Path
from typing import Any, Dict, List

from src.tools.base_tool import BaseTool
from src.tools.filesystem.sandbox import Sandbox
from src.utils.logger import logger

# å·²çŸ¥çš„äºŒè¿›åˆ¶/å¯Œæ ¼å¼æ–‡ä»¶æ‰©å±•åï¼Œæ— æ³•ä»¥æ–‡æœ¬æ–¹å¼æœ‰æ•ˆè¯»å–
_BINARY_EXTENSIONS: set[str] = {
    # å‹ç¼©/å½’æ¡£
    ".zip", ".tar", ".gz", ".bz2", ".7z", ".rar", ".xz",
    # å›¾ç‰‡
    ".png", ".jpg", ".jpeg", ".gif", ".bmp", ".ico", ".webp", ".svg", ".tiff",
    # éŸ³è§†é¢‘
    ".mp3", ".mp4", ".avi", ".mov", ".mkv", ".wav", ".flac", ".ogg",
    # å¯æ‰§è¡Œ/å­—èŠ‚ç 
    ".exe", ".dll", ".so", ".dylib", ".pyc", ".pyo", ".class", ".o",
    # æ•°æ®åº“/äºŒè¿›åˆ¶æ•°æ®
    ".sqlite", ".db", ".bin", ".dat", ".pkl", ".pickle",
    # PDF
    ".pdf",
    # å­—ä½“
    ".ttf", ".otf", ".woff", ".woff2",
    # Office æ–‡æ¡£ï¼ˆä¸å« Excelï¼ŒExcel å·²æ”¯æŒè§£æï¼‰
    ".docx", ".doc", ".pptx", ".ppt",
}

# å¯é€šè¿‡ä¸“ç”¨è§£æå™¨è¯»å–çš„å¯Œæ ¼å¼æ–‡ä»¶æ‰©å±•å
_EXCEL_EXTENSIONS: set[str] = {".xlsx", ".xls"}


def _is_binary_file(file_path: Path) -> bool:
    """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºå·²çŸ¥çš„äºŒè¿›åˆ¶/å¯Œæ ¼å¼æ–‡ä»¶ã€‚"""
    return file_path.suffix.lower() in _BINARY_EXTENSIONS


def _binary_file_hint(file_path: Path) -> str:
    """ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ç”Ÿæˆå‹å¥½çš„æç¤ºä¿¡æ¯ã€‚"""
    suffix = file_path.suffix.lower()
    hints = {
        ".docx": "Word æ–‡æ¡£",
        ".doc": "Word æ–‡æ¡£ï¼ˆæ—§ç‰ˆï¼‰",
        ".pptx": "PowerPoint æ¼”ç¤ºæ–‡ç¨¿",
        ".ppt": "PowerPoint æ¼”ç¤ºæ–‡ç¨¿ï¼ˆæ—§ç‰ˆï¼‰",
        ".pdf": "PDF æ–‡æ¡£",
        ".zip": "ZIP å‹ç¼©åŒ…",
        ".tar": "TAR å½’æ¡£",
        ".gz": "GZip å‹ç¼©æ–‡ä»¶",
    }
    file_type = hints.get(suffix, f"{suffix} äºŒè¿›åˆ¶æ–‡ä»¶")
    return (
        f"âš ï¸ æ— æ³•ä»¥æ–‡æœ¬æ–¹å¼è¯»å–: {file_path.name}\n"
        f"æ–‡ä»¶ç±»å‹: {file_type}\n"
        f"å»ºè®®: å¦‚æœæ˜¯ PDFï¼Œè¯·é€šè¿‡çŸ¥è¯†åº“ä¸Šä¼ åŠŸèƒ½å¯¼å…¥ã€‚"
    )


def _format_size(size: int) -> str:
    """å°†å­—èŠ‚æ•°æ ¼å¼åŒ–ä¸ºäººç±»å¯è¯»çš„å¤§å°ã€‚"""
    for unit in ("B", "KB", "MB", "GB"):
        if size < 1024:
            return f"{size:.0f}{unit}" if unit == "B" else f"{size:.1f}{unit}"
        size /= 1024
    return f"{size:.1f}TB"


def _format_time(ts: float) -> str:
    """å°†æ—¶é—´æˆ³æ ¼å¼åŒ–ä¸ºå¯è¯»å­—ç¬¦ä¸²ã€‚"""
    return time.strftime("%Y-%m-%d %H:%M", time.localtime(ts))


class FileReaderTool(BaseTool):
    """æ–‡ä»¶è¯»å–ä¸æœç´¢å·¥å…·ã€‚

    é€šè¿‡ Sandbox é™åˆ¶æ‰€æœ‰æ“ä½œåœ¨å®‰å…¨ç›®å½•å†…ï¼Œ
    æ”¯æŒç›®å½•æµè§ˆã€æ–‡ä»¶æŸ¥æ‰¾ã€å†…å®¹æœç´¢ã€æ–‡ä»¶è¯»å–ã€‚
    """

    def __init__(self, sandbox: Sandbox):
        self._sandbox = sandbox

    @property
    def name(self) -> str:
        return "file_reader"

    @property
    def description(self) -> str:
        return (
            "è¯»å–å’Œæœç´¢æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿã€‚æ”¯æŒ 5 ç§æ“ä½œï¼ˆé€šè¿‡ action å‚æ•°æŒ‡å®šï¼‰ï¼š\n"
            "1. list_allowed_dirs: åˆ—å‡ºæ‰€æœ‰å¯è®¿é—®çš„ç›®å½•åŠå…¶æƒé™ï¼ˆä¸éœ€è¦ path å‚æ•°ï¼‰\n"
            "2. list_dir: åˆ—å‡ºç›®å½•å†…å®¹ï¼ˆæ–‡ä»¶åã€å¤§å°ã€ä¿®æ”¹æ—¶é—´ï¼‰\n"
            "3. find_files: æŒ‰æ–‡ä»¶åæ¨¡å¼æŸ¥æ‰¾ï¼ˆå¦‚ *.pyã€test_*ï¼‰\n"
            "4. search_content: åœ¨æ–‡ä»¶å†…å®¹ä¸­æœç´¢æ–‡æœ¬ï¼ˆç±»ä¼¼ grepï¼‰\n"
            "5. read_file: è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆæ”¯æŒæŒ‡å®šèµ·å§‹è¡Œå’Œè¡Œæ•°ï¼Œæ”¯æŒ .xlsx/.xls Excel æ–‡ä»¶è‡ªåŠ¨è§£æä¸ºè¡¨æ ¼ï¼‰\n"
            "é€‚ç”¨åœºæ™¯ï¼šéœ€è¦æµè§ˆç›®å½•ç»“æ„ã€æŸ¥æ‰¾ç‰¹å®šæ–‡ä»¶ã€æœç´¢ä»£ç ä¸­çš„å…³é”®è¯ã€é˜…è¯»æ–‡ä»¶å†…å®¹æ—¶ä½¿ç”¨ã€‚\n"
            "ä¸é€‚ç”¨ï¼šä¿®æ”¹æ–‡ä»¶è¯·ä½¿ç”¨ file_writer å·¥å…·ã€‚\n"
            "æç¤ºï¼šå¯ä»¥å…ˆç”¨ list_allowed_dirs æŸ¥çœ‹å¯è®¿é—®å“ªäº›ç›®å½•ã€‚è·¯å¾„æ”¯æŒç›¸å¯¹è·¯å¾„ã€ç»å¯¹è·¯å¾„å’Œ ~ è·¯å¾„ã€‚\n"
            f"é™åˆ¶ï¼šå•æ–‡ä»¶æœ€å¤§ {_format_size(self._sandbox.max_file_size)}ã€‚"
        )

    @property
    def parameters(self) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "action": {
                    "type": "string",
                    "enum": ["list_allowed_dirs", "list_dir", "find_files", "search_content", "read_file"],
                    "description": "æ“ä½œç±»å‹",
                },
                "path": {
                    "type": "string",
                    "description": (
                        "ç›®æ ‡è·¯å¾„ã€‚æ”¯æŒç›¸å¯¹è·¯å¾„ï¼ˆåŸºäºé»˜è®¤å·¥ä½œç›®å½•ï¼‰ã€ç»å¯¹è·¯å¾„ã€~ è·¯å¾„ã€‚"
                        "list_allowed_dirs: ä¸éœ€è¦æ­¤å‚æ•°ï¼›"
                        "list_dir/find_files/search_content: ç›®æ ‡ç›®å½•ï¼›read_file: æ–‡ä»¶è·¯å¾„"
                    ),
                },
                "pattern": {
                    "type": "string",
                    "description": (
                        "find_files: glob æ¨¡å¼ï¼ˆå¦‚ *.pyã€**/test_*.pyï¼‰ï¼›"
                        "search_content: æœç´¢æ–‡æœ¬æˆ–æ­£åˆ™è¡¨è¾¾å¼"
                    ),
                },
                "max_depth": {
                    "type": "integer",
                    "description": "æœç´¢æœ€å¤§æ·±åº¦ï¼Œé»˜è®¤ 3",
                },
                "offset": {
                    "type": "integer",
                    "description": "read_file: èµ·å§‹è¡Œå·ï¼ˆä» 1 å¼€å§‹ï¼‰ï¼Œé»˜è®¤ä»å¤´è¯»å–",
                },
                "limit": {
                    "type": "integer",
                    "description": "read_file: è¯»å–è¡Œæ•°ï¼Œé»˜è®¤è¯»å–å…¨éƒ¨",
                },
            },
            "required": ["action"],
        }

    def execute(self, action: str, path: str = ".", **kwargs) -> str:
        """æ ¹æ® action åˆ†å‘åˆ°å…·ä½“æ“ä½œã€‚"""
        dispatch = {
            "list_allowed_dirs": self._list_allowed_dirs,
            "list_dir": self._list_dir,
            "find_files": self._find_files,
            "search_content": self._search_content,
            "read_file": self._read_file,
        }

        handler = dispatch.get(action)
        if not handler:
            return f"æœªçŸ¥æ“ä½œ: {action}ã€‚æ”¯æŒçš„æ“ä½œ: {list(dispatch.keys())}"

        try:
            return handler(path, **kwargs)
        except (PermissionError, FileNotFoundError, ValueError) as e:
            return f"æ“ä½œå¤±è´¥: {e}"
        except Exception as e:
            logger.error("file_reader.{} å¼‚å¸¸: {}", action, e)
            return f"æ“ä½œå¼‚å¸¸: {e}"

    # â”€â”€ å…·ä½“æ“ä½œ â”€â”€

    def _list_allowed_dirs(self, path: str = ".", **kwargs) -> str:
        """åˆ—å‡ºæ‰€æœ‰å¯è®¿é—®çš„ç›®å½•åŠæƒé™ã€‚"""
        return self._sandbox.list_allowed_dirs()

    def _list_dir(self, path: str, max_depth: int = 3, **kwargs) -> str:
        """åˆ—å‡ºç›®å½•å†…å®¹ï¼Œå«æ–‡ä»¶å¤§å°å’Œä¿®æ”¹æ—¶é—´ã€‚"""
        dir_path = self._sandbox.validate_dir(path)
        max_depth = min(max_depth, self._sandbox.max_depth)

        lines: List[str] = [f"ğŸ“ {self._sandbox.relative_to_root(dir_path)}/"]
        self._walk_dir(dir_path, lines, prefix="", depth=0, max_depth=max_depth)

        if len(lines) == 1:
            lines.append("  (ç©ºç›®å½•)")

        return "\n".join(lines)

    def _walk_dir(
        self, dir_path: Path, lines: List[str],
        prefix: str, depth: int, max_depth: int,
    ) -> None:
        """é€’å½’éå†ç›®å½•ï¼Œæ„å»ºæ ‘å½¢è¾“å‡ºã€‚"""
        if depth >= max_depth:
            return

        try:
            entries = sorted(dir_path.iterdir(), key=lambda e: (not e.is_dir(), e.name.lower()))
        except PermissionError:
            lines.append(f"{prefix}  âš ï¸ æƒé™ä¸è¶³")
            return

        # é™åˆ¶ç»“æœæ•°é‡
        count = 0
        for entry in entries:
            if self._sandbox.is_excluded(entry):
                continue

            count += 1
            if count > self._sandbox.max_results:
                lines.append(f"{prefix}  ... è¿˜æœ‰æ›´å¤šé¡¹ï¼ˆå·²è¾¾ä¸Šé™ {self._sandbox.max_results}ï¼‰")
                break

            rel = self._sandbox.relative_to_root(entry)
            if entry.is_dir():
                lines.append(f"{prefix}  ğŸ“ {entry.name}/")
                self._walk_dir(entry, lines, prefix=prefix + "  ", depth=depth + 1, max_depth=max_depth)
            else:
                stat = entry.stat()
                size = _format_size(stat.st_size)
                mtime = _format_time(stat.st_mtime)
                lines.append(f"{prefix}  ğŸ“„ {entry.name}  ({size}, {mtime})")

    def _find_files(self, path: str, pattern: str = "*", max_depth: int = 3, **kwargs) -> str:
        """æŒ‰ glob æ¨¡å¼æŸ¥æ‰¾æ–‡ä»¶ã€‚"""
        dir_path = self._sandbox.validate_dir(path)
        max_depth = min(max_depth, self._sandbox.max_depth)

        results: List[str] = []
        self._glob_search(dir_path, pattern, results, depth=0, max_depth=max_depth)

        if not results:
            return f"åœ¨ {self._sandbox.relative_to_root(dir_path)}/ ä¸‹æœªæ‰¾åˆ°åŒ¹é… '{pattern}' çš„æ–‡ä»¶"

        header = f"æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é… '{pattern}' çš„æ–‡ä»¶ï¼š\n"
        return header + "\n".join(results)

    def _glob_search(
        self, dir_path: Path, pattern: str,
        results: List[str], depth: int, max_depth: int,
    ) -> None:
        """é€’å½’ glob æœç´¢ã€‚"""
        if depth >= max_depth or len(results) >= self._sandbox.max_results:
            return

        try:
            entries = sorted(dir_path.iterdir(), key=lambda e: e.name.lower())
        except PermissionError:
            return

        for entry in entries:
            if self._sandbox.is_excluded(entry):
                continue

            if len(results) >= self._sandbox.max_results:
                results.append(f"... ç»“æœå·²è¾¾ä¸Šé™ ({self._sandbox.max_results})")
                return

            if entry.is_file() and entry.match(pattern):
                rel = self._sandbox.relative_to_root(entry)
                stat = entry.stat()
                results.append(f"  {rel}  ({_format_size(stat.st_size)})")
            elif entry.is_dir():
                self._glob_search(entry, pattern, results, depth + 1, max_depth)

    def _search_content(self, path: str, pattern: str = "", max_depth: int = 3, **kwargs) -> str:
        """åœ¨æ–‡ä»¶å†…å®¹ä¸­æœç´¢æ–‡æœ¬ï¼ˆç±»ä¼¼ grepï¼‰ã€‚"""
        if not pattern:
            return "search_content éœ€è¦æä¾› pattern å‚æ•°ï¼ˆæœç´¢æ–‡æœ¬æˆ–æ­£åˆ™è¡¨è¾¾å¼ï¼‰"

        dir_path = self._sandbox.validate_dir(path)
        max_depth = min(max_depth, self._sandbox.max_depth)

        # ç¼–è¯‘æ­£åˆ™ï¼ˆå¦‚æœæ˜¯æ™®é€šæ–‡æœ¬ï¼Œre.escape å¤„ç†ï¼‰
        try:
            regex = re.compile(pattern, re.IGNORECASE)
        except re.error:
            # ç”¨æˆ·è¾“å…¥çš„ä¸æ˜¯åˆæ³•æ­£åˆ™ï¼Œä½œä¸ºæ™®é€šæ–‡æœ¬æœç´¢
            regex = re.compile(re.escape(pattern), re.IGNORECASE)

        matches: List[str] = []
        self._grep_search(dir_path, regex, matches, depth=0, max_depth=max_depth)

        if not matches:
            return f"åœ¨ {self._sandbox.relative_to_root(dir_path)}/ ä¸‹æœªæ‰¾åˆ°åŒ…å« '{pattern}' çš„å†…å®¹"

        header = f"æœç´¢ '{pattern}' æ‰¾åˆ° {len(matches)} å¤„åŒ¹é…ï¼š\n"
        return header + "\n".join(matches)

    def _grep_search(
        self, dir_path: Path, regex: re.Pattern,
        matches: List[str], depth: int, max_depth: int,
    ) -> None:
        """é€’å½’æœç´¢æ–‡ä»¶å†…å®¹ã€‚"""
        if depth >= max_depth or len(matches) >= self._sandbox.max_results:
            return

        try:
            entries = sorted(dir_path.iterdir(), key=lambda e: e.name.lower())
        except PermissionError:
            return

        for entry in entries:
            if self._sandbox.is_excluded(entry):
                continue

            if len(matches) >= self._sandbox.max_results:
                matches.append(f"... ç»“æœå·²è¾¾ä¸Šé™ ({self._sandbox.max_results})")
                return

            if entry.is_dir():
                self._grep_search(entry, regex, matches, depth + 1, max_depth)
            elif entry.is_file():
                self._search_in_file(entry, regex, matches)

    def _search_in_file(self, file_path: Path, regex: re.Pattern, matches: List[str]) -> None:
        """åœ¨å•ä¸ªæ–‡ä»¶ä¸­æœç´¢åŒ¹é…å†…å®¹ã€‚"""
        # è·³è¿‡äºŒè¿›åˆ¶æ–‡ä»¶
        if _is_binary_file(file_path):
            return
        # è·³è¿‡è¿‡å¤§æ–‡ä»¶
        try:
            size = file_path.stat().st_size
            if size > self._sandbox.max_file_size:
                return
        except OSError:
            return

        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                rel_path = self._sandbox.relative_to_root(file_path)
                for line_no, line in enumerate(f, 1):
                    if len(matches) >= self._sandbox.max_results:
                        return
                    if regex.search(line):
                        # æˆªæ–­è¿‡é•¿çš„è¡Œ
                        display_line = line.rstrip()
                        if len(display_line) > 200:
                            display_line = display_line[:200] + "..."
                        matches.append(f"  {rel_path}:{line_no}: {display_line}")
        except (UnicodeDecodeError, OSError):
            pass  # è·³è¿‡äºŒè¿›åˆ¶æ–‡ä»¶æˆ–ä¸å¯è¯»æ–‡ä»¶

    def _read_file(self, path: str, offset: int = 0, limit: int = 0, **kwargs) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒåˆ†æ®µè¯»å–ã€‚"""
        file_path = self._sandbox.validate_file_for_read(path)

        # Excel æ–‡ä»¶ä½¿ç”¨ä¸“ç”¨è§£æå™¨
        if file_path.suffix.lower() in _EXCEL_EXTENSIONS:
            return self._read_excel(file_path, offset=offset, limit=limit)

        # å…¶ä»–äºŒè¿›åˆ¶æ–‡ä»¶ç›´æ¥è¿”å›å‹å¥½æç¤º
        if _is_binary_file(file_path):
            return _binary_file_hint(file_path)

        with open(file_path, "r", encoding="utf-8", errors="replace") as f:
            lines = f.readlines()

        total_lines = len(lines)
        rel_path = self._sandbox.relative_to_root(file_path)

        # åˆ†æ®µè¯»å–
        if offset > 0:
            start = max(0, offset - 1)  # ç”¨æˆ·ä¼ çš„æ˜¯ 1-based è¡Œå·
        else:
            start = 0

        if limit > 0:
            end = min(start + limit, total_lines)
        else:
            end = total_lines

        selected = lines[start:end]

        # æ·»åŠ è¡Œå·
        numbered_lines = []
        for i, line in enumerate(selected, start + 1):
            numbered_lines.append(f"{i:>4}| {line.rstrip()}")

        content = "\n".join(numbered_lines)

        # å…ƒä¿¡æ¯å¤´
        header = f"ğŸ“„ {rel_path} (å…± {total_lines} è¡Œ"
        if start > 0 or end < total_lines:
            header += f", æ˜¾ç¤ºç¬¬ {start + 1}-{end} è¡Œ"
        header += ")\n"

        return header + content

    def _read_excel(self, file_path: Path, offset: int = 0, limit: int = 0) -> str:
        """ä½¿ç”¨ openpyxl è¯»å– Excel æ–‡ä»¶ï¼Œè¾“å‡ºä¸º Markdown è¡¨æ ¼ã€‚

        æ”¯æŒå¤š Sheetã€åˆ†æ®µè¯»å–ï¼ˆoffset/limit æŒ‰æ•°æ®è¡Œè®¡ç®—ï¼Œä¸å«è¡¨å¤´ï¼‰ã€‚
        """
        try:
            from openpyxl import load_workbook
        except ImportError:
            return (
                "âš ï¸ ç¼ºå°‘ Excel è§£æä¾èµ–ï¼Œè¯·æ‰§è¡Œ: pip install openpyxl\n"
                f"æ–‡ä»¶: {file_path.name}"
            )

        rel_path = self._sandbox.relative_to_root(file_path)
        max_rows_per_sheet = 200  # å•ä¸ª Sheet æœ€å¤§è¾“å‡ºè¡Œæ•°ï¼Œé˜²æ­¢è¶…å¤§æ–‡ä»¶çˆ† token

        try:
            wb = load_workbook(file_path, read_only=True, data_only=True)
        except Exception as e:
            return f"âš ï¸ Excel æ–‡ä»¶è¯»å–å¤±è´¥: {file_path.name}\né”™è¯¯: {e}"

        try:
            sections: List[str] = []

            for sheet_name in wb.sheetnames:
                ws = wb[sheet_name]
                rows = list(ws.iter_rows(values_only=True))

                if not rows:
                    sections.append(f"### Sheet: {sheet_name}\n(ç©ºè¡¨)")
                    continue

                # ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
                headers = [str(c) if c is not None else "" for c in rows[0]]
                data_rows = rows[1:]
                total_data_rows = len(data_rows)

                # åˆ†æ®µè¯»å–
                start = max(0, offset - 1) if offset > 0 else 0
                end = min(start + limit, total_data_rows) if limit > 0 else total_data_rows
                # æˆªæ–­ä¿æŠ¤
                if end - start > max_rows_per_sheet:
                    end = start + max_rows_per_sheet

                selected_rows = data_rows[start:end]

                # æ„å»º Markdown è¡¨æ ¼
                col_count = len(headers)
                header_line = "| " + " | ".join(headers) + " |"
                separator = "| " + " | ".join(["---"] * col_count) + " |"

                table_lines = [header_line, separator]
                for row in selected_rows:
                    cells = []
                    for i in range(col_count):
                        val = row[i] if i < len(row) else None
                        cell_str = str(val) if val is not None else ""
                        # è½¬ä¹‰ Markdown ç®¡é“ç¬¦ï¼Œæˆªæ–­è¿‡é•¿å•å…ƒæ ¼
                        cell_str = cell_str.replace("|", "\\|").replace("\n", " ")
                        if len(cell_str) > 100:
                            cell_str = cell_str[:100] + "..."
                        cells.append(cell_str)
                    table_lines.append("| " + " | ".join(cells) + " |")

                # Sheet æ ‡é¢˜
                sheet_header = f"### Sheet: {sheet_name} ({total_data_rows} è¡Œ Ã— {col_count} åˆ—"
                if start > 0 or end < total_data_rows:
                    sheet_header += f", æ˜¾ç¤ºç¬¬ {start + 1}-{end} è¡Œ"
                if end - start >= max_rows_per_sheet and end < total_data_rows:
                    sheet_header += f", å·²æˆªæ–­"
                sheet_header += ")"

                sections.append(sheet_header + "\n" + "\n".join(table_lines))

            file_header = f"ğŸ“Š {rel_path} ({len(wb.sheetnames)} ä¸ª Sheet)\n"
            return file_header + "\n\n".join(sections)
        finally:
            wb.close()
