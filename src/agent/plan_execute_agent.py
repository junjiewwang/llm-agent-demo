"""Plan-and-Execute Agent å®ç°ã€‚

æ¶æ„ï¼šPlannerï¼ˆLLM ç”Ÿæˆè®¡åˆ’ï¼‰â†’ Executorï¼ˆæ¯æ­¥å¤ç”¨ ReAct å­å¾ªç¯ï¼‰â†’ Monitorï¼ˆReplan åˆ¤æ–­ï¼‰ã€‚

æ ¸å¿ƒæµç¨‹ï¼š
1. ç”¨æˆ·è¾“å…¥ â†’ Planner ç”Ÿæˆ Planï¼ˆæ­¥éª¤åˆ—è¡¨ï¼‰
2. é€æ­¥æ‰§è¡Œï¼šæ¯æ­¥æ„é€ å­ç›®æ ‡ â†’ å¤ç”¨ ReAct å­å¾ªç¯å®Œæˆ â†’ è®°å½•ç»“æœ
3. æ¯æ­¥æ‰§è¡Œååˆ¤æ–­æ˜¯å¦éœ€è¦ Replanï¼ˆæ­¥éª¤å¤±è´¥ / ç»“æœåç¦»é¢„æœŸï¼‰
4. æ‰€æœ‰æ­¥éª¤å®Œæˆ â†’ ç»¼åˆå„æ­¥ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”

ä¸ ReActAgent çš„å…³ç³»ï¼š
- PlanExecuteAgent æ˜¯ ReAct çš„ä¸Šå±‚ç¼–æ’ï¼Œä¸æ˜¯æ›¿ä»£
- æ¯ä¸ªæ­¥éª¤çš„æ‰§è¡Œä»ç„¶æ˜¯ä¸€ä¸ªå®Œæ•´çš„ ReAct å¾ªç¯ï¼ˆThink â†’ Act â†’ Observeï¼‰
- PlanExecuteAgent é¢å¤–æä¾›ï¼šä»»åŠ¡åˆ†è§£ã€æ­¥éª¤è·Ÿè¸ªã€Replan èƒ½åŠ›
"""

import time
from typing import Optional, TYPE_CHECKING

from src.agent.base_agent import BaseAgent, OnEventCallback, WaitForConfirmation
from src.agent.events import AgentEvent, AgentStoppedError, EventType
from src.agent.loop_detector import LoopDetector
from src.agent.metrics import RunMetrics
from src.agent.plan import Plan, PlanStep, StepStatus, create_plan, replan
from src.agent.tool_executor import ToolExecutorMixin
from src.config import settings
from src.context.builder import ContextBuilder
from src.environment.adapter_base import EnvironmentAdapter
from src.llm.base_client import BaseLLMClient, Message, Role
from src.memory.conversation import ConversationMemory
from src.memory.vector_store import VectorStore
from src.observability import get_tracer
from src.observability.instruments import trace_span, set_span_content
from src.tools.base_tool import ToolRegistry
from src.utils.logger import logger

if TYPE_CHECKING:
    from src.rag.knowledge_base import KnowledgeBase
    from src.skills.router import SkillRouter

_tracer = get_tracer(__name__)

# æ­¥éª¤æ‰§è¡Œçš„å­ç›®æ ‡ prompt æ¨¡æ¿
_STEP_PROMPT_TEMPLATE = """ä½ æ­£åœ¨æ‰§è¡Œä¸€ä¸ªå¤šæ­¥éª¤è®¡åˆ’çš„ç¬¬ {step_index}/{total_steps} æ­¥ã€‚

æ€»ç›®æ ‡ï¼š{goal}

å½“å‰æ­¥éª¤ï¼š{step_description}
{tool_hint_line}
{context_line}

è¯·ä¸“æ³¨å®Œæˆå½“å‰æ­¥éª¤ï¼Œç»™å‡ºè¿™ä¸€æ­¥çš„æ‰§è¡Œç»“æœã€‚
æç¤ºï¼šå¦‚æœå½“å‰æ­¥éª¤éœ€è¦è·å–å¤šé¡¹ç‹¬ç«‹ä¿¡æ¯ï¼Œè¯·åœ¨ä¸€æ¬¡å›å¤ä¸­åŒæ—¶è°ƒç”¨å¤šä¸ªå·¥å…·ï¼ˆå¹¶è¡Œï¼‰ï¼Œè€Œä¸æ˜¯é€ä¸ªè°ƒç”¨ï¼Œä»¥æé«˜æ‰§è¡Œæ•ˆç‡ã€‚

é‡è¦çº¦æŸï¼š
- å½“å·¥å…·å·²è¿”å›ç»“æœæ—¶ï¼Œä½ å¿…é¡»åŸºäºå·¥å…·è¿”å›çš„å®é™…æ•°æ®æ¥æ€»ç»“å’Œå›ç­”å½“å‰æ­¥éª¤çš„é—®é¢˜
- ä¸è¦å¿½ç•¥å·¥å…·ç»“æœï¼Œä¸è¦å›ç­”ä¸å½“å‰æ­¥éª¤æ— å…³çš„å†…å®¹
- ä½ çš„å›ç­”å¿…é¡»å›´ç»•ã€Œå½“å‰æ­¥éª¤ã€çš„ç›®æ ‡ï¼Œä¸è¦æè¿°ä½ çš„èƒ½åŠ›æˆ–å±€é™æ€§"""

# æœ€ç»ˆç»¼åˆå›ç­” prompt
_FINAL_SYNTHESIS_PROMPT = """ä½ åˆšåˆšå®Œæˆäº†ä¸€ä¸ªå¤šæ­¥éª¤è®¡åˆ’ã€‚è¯·æ ¹æ®å„æ­¥éª¤çš„æ‰§è¡Œç»“æœï¼Œç»™ç”¨æˆ·ä¸€ä¸ªå®Œæ•´ã€è¿è´¯çš„æœ€ç»ˆå›ç­”ã€‚

ç”¨æˆ·åŸå§‹é—®é¢˜ï¼š{goal}

å„æ­¥éª¤æ‰§è¡Œç»“æœï¼š
{step_results}

è¯·ç»¼åˆä»¥ä¸Šç»“æœï¼Œç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ä¸è¦é€æ­¥åˆ—ä¸¾æ‰§è¡Œè¿‡ç¨‹ï¼Œç›´æ¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚"""


class PlanExecuteAgent(BaseAgent, ToolExecutorMixin):
    """Plan-and-Execute Agentã€‚

    å…ˆé€šè¿‡ LLM å°†ç”¨æˆ·ä»»åŠ¡åˆ†è§£ä¸ºæ­¥éª¤åˆ—è¡¨ï¼ˆPlanï¼‰ï¼Œ
    ç„¶åé€æ­¥æ‰§è¡Œæ¯ä¸ªæ­¥éª¤ï¼ˆæ¯æ­¥å¤ç”¨ ReAct å­å¾ªç¯ï¼‰ï¼Œ
    æœ€ç»ˆç»¼åˆæ‰€æœ‰æ­¥éª¤ç»“æœç»™å‡ºæœ€ç»ˆå›ç­”ã€‚

    æ”¯æŒï¼š
    - ä»»åŠ¡åˆ†è§£ï¼šLLM è‡ªåŠ¨å°†å¤æ‚ä»»åŠ¡æ‹†åˆ†ä¸º 3-7 æ­¥
    - æ­¥éª¤è·Ÿè¸ªï¼šæ¯æ­¥æœ‰ç‹¬ç«‹çš„çŠ¶æ€ï¼ˆPENDING â†’ RUNNING â†’ COMPLETED/FAILEDï¼‰
    - Replanï¼šæ­¥éª¤å¤±è´¥æ—¶å¯é‡æ–°è§„åˆ’å‰©ä½™æ­¥éª¤ï¼ˆæœ€å¤š MAX_REPLAN æ¬¡ï¼‰
    - äº‹ä»¶é€šçŸ¥ï¼šPLAN_CREATED / STEP_START / STEP_DONE / REPLAN å…¨é“¾è·¯äº‹ä»¶
    - å¯è§‚æµ‹æ€§ï¼šå…±äº« RunMetricsï¼Œè®°å½•æ‰€æœ‰å­å¾ªç¯çš„ LLM/å·¥å…·è°ƒç”¨
    """

    def __init__(
        self,
        llm_client: BaseLLMClient,
        tool_registry: ToolRegistry,
        memory: ConversationMemory,
        context_builder: ContextBuilder,
        vector_store: Optional[VectorStore] = None,
        knowledge_base: Optional["KnowledgeBase"] = None,
        skill_router: Optional["SkillRouter"] = None,
        env_adapter: Optional[EnvironmentAdapter] = None,
        max_iterations: Optional[int] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
    ):
        super().__init__(llm_client, tool_registry, memory)
        self._context_builder = context_builder
        self._vector_store = vector_store
        self._knowledge_base = knowledge_base
        self._skill_router = skill_router
        self._env_adapter = env_adapter
        self._max_iterations = max_iterations or settings.agent.max_iterations
        self._temperature = temperature or settings.agent.temperature
        self._step_temperature = settings.agent.step_temperature  # æ­¥éª¤æ‰§è¡Œç‹¬ç«‹ä½æ¸©
        self._max_tokens = max_tokens or settings.agent.max_tokens
        self._last_metrics: Optional[RunMetrics] = None

        # æ¯æ­¥å­å¾ªç¯çš„æœ€å¤§è¿­ä»£æ•°ï¼ˆæ¯”ä¸» Agent å°‘ï¼Œé¿å…å•æ­¥è€—æ—¶è¿‡é•¿ï¼‰
        self._step_max_iterations = min(self._max_iterations, 10)
        self._loop_detector = LoopDetector()
        self._current_snapshot_pos: Optional[int] = None  # å½“å‰æ­¥éª¤çš„ Scratchpad å¿«ç…§ä½ç½®

    @property
    def context_builder(self) -> ContextBuilder:
        return self._context_builder

    @property
    def last_metrics(self) -> Optional[RunMetrics]:
        return self._last_metrics

    def run(
        self,
        user_input: str,
        on_event: OnEventCallback = None,
        wait_for_confirmation: WaitForConfirmation = None,
    ) -> str:
        """Plan-and-Execute ä¸»æµç¨‹ã€‚"""
        metrics = RunMetrics(max_iterations=self._max_iterations)

        def _emit(event: AgentEvent) -> None:
            if on_event:
                try:
                    on_event(event)
                except AgentStoppedError:
                    raise
                except Exception as e:
                    logger.warning("äº‹ä»¶å›è°ƒå¼‚å¸¸: {}", e)

        with trace_span(_tracer, "plan_execute_agent.run",
                        {"agent.type": "plan_execute"}) as span:
            set_span_content(span, "agent.input", user_input)
            try:
                result = self._run_plan_execute(
                    user_input, metrics, _emit, wait_for_confirmation,
                )
                set_span_content(span, "agent.output", result)
                return result
            except AgentStoppedError:
                logger.info("ç”¨æˆ·åœæ­¢äº† Plan-Execute Agent | è¿­ä»£: {}", metrics.iterations)
                self._context_builder.clear_injections()
                metrics.finish()
                self._last_metrics = metrics
                raise

    def _run_plan_execute(
        self, user_input: str, metrics: RunMetrics,
        _emit, wait_for_confirmation: WaitForConfirmation = None,
    ) -> str:
        """Plan-Execute æ ¸å¿ƒæµç¨‹ã€‚"""

        # â”€â”€ Phase 1: ç”Ÿæˆè®¡åˆ’ï¼ˆé™é»˜è°ƒç”¨ï¼Œç®€å•ä»»åŠ¡ä¸æ‰“æ‰°ç”¨æˆ·ï¼‰ â”€â”€
        plan = create_plan(self._llm, user_input, temperature=0.3)

        if not plan or len(plan.steps) == 0:
            logger.warning("è®¡åˆ’ç”Ÿæˆå¤±è´¥æˆ–ä»»åŠ¡è¾ƒç®€å•ï¼Œå›é€€åˆ°ç›´æ¥å›ç­”")
            return self._fallback_direct_answer(user_input, metrics, _emit, wait_for_confirmation)

        # å‘é€ PLAN_CREATED äº‹ä»¶
        _emit(AgentEvent(
            type=EventType.PLAN_CREATED,
            plan=plan.to_dict(),
            total_steps=len(plan.steps),
            message=f"å·²ç”Ÿæˆ {len(plan.steps)} æ­¥æ‰§è¡Œè®¡åˆ’",
        ))

        logger.info("Plan-Execute å¼€å§‹ | ç›®æ ‡: {} | æ­¥éª¤æ•°: {}", user_input[:50], len(plan.steps))

        # å°†ç”¨æˆ·åŸå§‹æ¶ˆæ¯å†™å…¥å¯¹è¯å†å²ï¼ˆæŒä¹…åŒ–ï¼Œä¸åœ¨ Scratchpad èŒƒå›´å†…ï¼‰
        self._memory.add_user_message(user_input)

        # â”€â”€ Phase 2: é€æ­¥æ‰§è¡Œ â”€â”€
        while not plan.is_complete:
            step = plan.current_step
            if step is None:
                break

            step.status = StepStatus.RUNNING

            _emit(AgentEvent(
                type=EventType.STEP_START,
                step_id=step.id,
                step_index=plan.current_step_index,
                total_steps=len(plan.steps),
                message=step.description,
            ))

            logger.info("æ‰§è¡Œæ­¥éª¤ {}/{}: {}", plan.current_step_index + 1,
                        len(plan.steps), step.description[:80])

            # æ‰§è¡Œå­å¾ªç¯
            step_result = self._execute_step(
                plan, step, metrics, _emit, wait_for_confirmation,
            )

            if step_result is not None:
                step.status = StepStatus.COMPLETED
                step.result_summary = step_result[:500]
            else:
                step.status = StepStatus.FAILED
                step.result_summary = "æ‰§è¡Œå¤±è´¥"

            _emit(AgentEvent(
                type=EventType.STEP_DONE,
                step_id=step.id,
                step_index=plan.current_step_index,
                total_steps=len(plan.steps),
                step_status=step.status.value,
                message=step.result_summary[:200],
            ))

            logger.info("æ­¥éª¤ {} å®Œæˆ | çŠ¶æ€: {} | ç´¯è®¡æŒ‡æ ‡: {} | ç»“æœ: {}",
                        step.id, step.status.value, metrics.summary(),
                        step.result_summary[:100])

            # â”€â”€ Phase 2.5: Replan åˆ¤æ–­ â”€â”€
            if step.status == StepStatus.FAILED and plan.replan_count < Plan.MAX_REPLAN:
                new_steps = self._try_replan(plan, _emit)
                if new_steps is not None:
                    # æ›¿æ¢å‰©ä½™æ­¥éª¤
                    plan.steps = plan.completed_steps + [step] + new_steps
                    plan.replan_count += 1
                    # current_step_index æŒ‡å‘å¤±è´¥æ­¥éª¤çš„ä¸‹ä¸€ä¸ª
                    plan.current_step_index = len(plan.completed_steps) + 1
                    continue

            plan.advance()

        # â”€â”€ Phase 3: ç»¼åˆå›ç­” â”€â”€
        final_answer = self._synthesize_answer(plan, metrics)
        self._context_builder.clear_injections()
        metrics.finish()
        self._last_metrics = metrics
        logger.info("Plan-Execute å®Œæˆ | {} | {}", plan.progress_summary, metrics.summary())
        return final_answer

    def _execute_step(
        self, plan: Plan, step: PlanStep, metrics: RunMetrics,
        _emit, wait_for_confirmation: WaitForConfirmation = None,
    ) -> Optional[str]:
        """æ‰§è¡Œè®¡åˆ’ä¸­çš„å•ä¸ªæ­¥éª¤ï¼Œå¤ç”¨ ReAct å­å¾ªç¯ã€‚

        é‡‡ç”¨ Scratchpad æ¶æ„å®ç°æ­¥éª¤çº§ä¸Šä¸‹æ–‡éš”ç¦»ï¼š
        1. snapshot() â€” è®°å½•æ­¥éª¤å¼€å§‹å‰çš„æ¶ˆæ¯ä½ç½®
        2. åœ¨ Scratchpad ä¸­æ‰§è¡Œ ReAct å­å¾ªç¯ï¼ˆThink â†’ Act â†’ Observeï¼‰
        3. rollback_to_snapshot() â€” é”€æ¯æ­¥éª¤çš„ä¸­é—´è¿‡ç¨‹æ¶ˆæ¯
        4. settle_step_result() â€” ä»…æ²‰æ·€ä¸€æ¡ç²¾ç®€çš„ç»“æœæ‘˜è¦

        è¿™å°† Token æ¶ˆè€—ä» O(kÂ²) é™ä½åˆ° O(k)ï¼šåç»­æ­¥éª¤åªçœ‹åˆ°å‰é¢æ­¥éª¤çš„
        ç»“æœæ‘˜è¦ï¼Œè€Œä¸æ˜¯å…¨éƒ¨çš„ä¸­é—´æ¨ç†å’Œå·¥å…·è¾“å‡ºã€‚

        Returns:
            æ­¥éª¤æ‰§è¡Œç»“æœæ–‡æœ¬ï¼Œå¤±è´¥è¿”å› Noneã€‚
        """
        # æ„é€ æ­¥éª¤å­ç›®æ ‡ promptï¼ˆåŒ…å«å·²å®Œæˆæ­¥éª¤çš„ç»“æœæ‘˜è¦ï¼‰
        context_parts = []
        for s in plan.completed_steps:
            context_parts.append(f"- {s.description}: {s.result_summary}")
        context_line = ""
        if context_parts:
            context_line = "å·²å®Œæˆçš„æ­¥éª¤ç»“æœï¼š\n" + "\n".join(context_parts)

        tool_hint_line = ""
        if step.tool_hint:
            tool_hint_line = f"å»ºè®®ä½¿ç”¨å·¥å…·ï¼š{step.tool_hint}"

        step_prompt = _STEP_PROMPT_TEMPLATE.format(
            step_index=plan.current_step_index + 1,
            total_steps=len(plan.steps),
            goal=plan.goal,
            step_description=step.description,
            tool_hint_line=tool_hint_line,
            context_line=context_line,
        )

        tools_schema = None

        # â”€â”€ Scratchpad: å¿«ç…§å½“å‰æ¶ˆæ¯ä½ç½® â”€â”€
        snapshot_pos = self._memory.snapshot()
        self._current_snapshot_pos = snapshot_pos
        # æ¯æ­¥å¼€å§‹æ—¶é‡ç½®å¾ªç¯æ£€æµ‹å™¨ï¼Œé¿å…è·¨æ­¥éª¤çš„è¯¯åˆ¤
        self._loop_detector.reset()
        # L3 ä»»åŠ¡åç¦»æ£€æµ‹ï¼šä» step æè¿°å’Œ tool_hint æ¨æ–­é¢„æœŸå·¥å…·
        expected_tools = self._infer_expected_tools(step)
        if expected_tools:
            self._loop_detector.set_expected_tools(expected_tools)

        try:
            # æ³¨å…¥çŸ¥è¯†ã€è®°å¿†ã€æŠ€èƒ½ï¼ˆé¦–æ­¥æ³¨å…¥ï¼Œåç»­å¤ç”¨ï¼‰
            if plan.current_step_index == 0:
                self._inject_context(plan.goal, metrics)
                # é¦–æ­¥æ—¶è®¾ç½® tools schema é¢„ç•™ï¼ˆtools åœ¨è¿è¡ŒæœŸé—´ä¸å˜ï¼‰
                tools_schema = self._tools.to_openai_tools() if len(self._tools) > 0 else None
                self._context_builder.set_tools_reserve(tools_schema)
            else:
                tools_schema = self._tools.to_openai_tools() if len(self._tools) > 0 else None

            # æ‰§è¡Œå™¨ä¸Šä¸‹æ–‡éš”ç¦»ï¼šæ¸…é™¤ Skill å’Œ Memory æ³¨å…¥
            # åŸå› ï¼šScratchpad å±€éƒ¨è§†å›¾ä¸­æ¶ˆæ¯æå°‘ï¼ˆSystem + step_prompt + å·¥å…·äº¤äº’ï¼‰ï¼Œ
            # ä»»ä½• SYSTEM çº§æ³¨å…¥ä¿¡æ¯çš„ç›¸å¯¹æƒé‡éƒ½ä¼šè¢«æåº¦æ”¾å¤§ï¼Œæœ‰"åŠ«æŒ"æ‰§è¡Œå™¨çš„é£é™©ï¼š
            # - Skill prompt â†’ LLM æŒ‰ Skill ç­–ç•¥è¡Œäº‹è€Œå¿½ç•¥ step_prompt
            # - é•¿æœŸè®°å¿† â†’ LLM æŠŠæ—§è®°å¿†å½“ä½œ"å…ˆä¾‹"ç…§æ¬ï¼ˆå¦‚"æ— æ³•æŸ¥è¯¢tokenç”¨é‡"ï¼‰
            # step_prompt å·²åŒ…å«æ€»ç›®æ ‡å’Œæ­¥éª¤æŒ‡ä»¤ï¼Œæ‰§è¡Œå™¨åªéœ€å·¥å…·å³å¯å®Œæˆä»»åŠ¡ã€‚
            # KB ä¿ç•™ï¼Œå› ä¸ºå®ƒæä¾›çš„æ˜¯ä¸å½“å‰æŸ¥è¯¢ç›´æ¥ç›¸å…³çš„äº‹å®æ€§æ–‡æ¡£ç‰‡æ®µã€‚
            self._context_builder.set_skills([])
            self._context_builder.set_memory([])

            # å°†å­ç›®æ ‡ä½œä¸ºç”¨æˆ·æ¶ˆæ¯åŠ å…¥å¯¹è¯ï¼ˆåœ¨ Scratchpad ä¸­ï¼‰
            self._memory.add_user_message(step_prompt)

            # æ£€æŸ¥å¹¶å‹ç¼©
            self._check_and_compress(_emit)

            # ReAct å­å¾ªç¯
            step_result = None
            for iteration in range(1, self._step_max_iterations + 1):
                metrics.iterations += 1

                logger.info("æ­¥éª¤ {}/{} è¿­ä»£ [{}/{}]",
                            plan.current_step_index + 1, len(plan.steps),
                            iteration, self._step_max_iterations)

                _emit(AgentEvent(
                    type=EventType.THINKING,
                    iteration=iteration,
                    max_iterations=self._step_max_iterations,
                ))

                # æ‰§è¡Œå™¨ä¸Šä¸‹æ–‡éš”ç¦»ï¼ˆLangGraph State Scopingï¼‰ï¼š
                # åªæºå¸¦ System Prompt + å½“å‰æ­¥éª¤çš„ Scratchpad æ¶ˆæ¯ï¼Œ
                # ä¸æºå¸¦ Scratchpad ä¹‹å‰çš„å…¨å±€å¯¹è¯å†å²ï¼Œé¿å…æ¶ˆæ¯æ¡æ•°è¶…é™ã€‚
                # step_prompt å·²åŒ…å«æ€»ç›®æ ‡å’Œå·²å®Œæˆæ­¥éª¤æ‘˜è¦ï¼Œæ— éœ€å†—ä½™å†å²ã€‚
                # compact_env=Trueï¼šè·³è¿‡å·¥å…·åˆ—è¡¨æ³¨å…¥ï¼ŒFunction Calling çš„ tools
                # å‚æ•°å·²æºå¸¦å®Œæ•´ schemaï¼Œæ— éœ€ SYSTEM æ¶ˆæ¯é‡å¤ï¼Œé¿å…å·¥å…·åˆ—è¡¨
                # æè¿°ä¸æ­¥éª¤æŒ‡ä»¤äº‰å¤º LLM æ³¨æ„åŠ›å¯¼è‡´å›ç­”åç¦»ã€‚
                # ä½¿ç”¨ memory ä¸­åŒæ­¥è°ƒæ•´åçš„å¿«ç…§ä½ç½®ï¼Œé˜²æ­¢ _smart_truncate
                # æˆªæ–­æ—§æ¶ˆæ¯å¯¼è‡´ snapshot_pos æŒ‡å‘ç©ºåŒºåŸŸã€‚
                effective_snapshot = self._memory.active_snapshot_pos
                if effective_snapshot is None:
                    effective_snapshot = snapshot_pos
                scoped_messages = self._memory.messages_from(effective_snapshot)
                context_messages = self._context_builder.build(
                    scoped_messages, compact_env=True,
                )

                # â”€â”€ å¯è§‚æµ‹æ€§ï¼šæ‰“å° LLM è°ƒç”¨å‰çš„ context æ‘˜è¦ â”€â”€
                self._log_context_summary(
                    context_messages, tools_schema,
                    step_index=plan.current_step_index + 1,
                    total_steps=len(plan.steps),
                    iteration=iteration,
                )

                response = self._llm.chat(
                    messages=context_messages,
                    tools=tools_schema,
                    temperature=self._step_temperature,
                    max_tokens=self._max_tokens,
                )
                metrics.record_llm_call(response.usage, call_type="step_chat")

                if not response.tool_calls:
                    self._memory.add_assistant_message(response)
                    logger.info("æ­¥éª¤ {}/{} ç»™å‡ºå›ç­” | è¿­ä»£: {}",
                                plan.current_step_index + 1, len(plan.steps), iteration)
                    _emit(AgentEvent(
                        type=EventType.ANSWERING,
                        iteration=iteration,
                        max_iterations=self._step_max_iterations,
                    ))
                    step_result = response.content or ""
                    break

                # å·¥å…·è°ƒç”¨
                logger.info("æ­¥éª¤ {}/{} è°ƒç”¨ {} ä¸ªå·¥å…·",
                            plan.current_step_index + 1, len(plan.steps),
                            len(response.tool_calls))
                self._memory.add_assistant_message(response)
                self.execute_tool_calls(
                    response.tool_calls, metrics, _emit, wait_for_confirmation,
                )

                # å¾ªç¯æ£€æµ‹ï¼šå¦‚æœæ£€æµ‹åˆ°é‡å¤è°ƒç”¨æ¨¡å¼ï¼Œæ’å…¥å¼•å¯¼ prompt
                loop_hint = self._loop_detector.get_loop_summary()
                if loop_hint:
                    logger.warning("æ­¥éª¤ {}/{} å¾ªç¯æ£€æµ‹è§¦å‘ï¼Œæ’å…¥å¼•å¯¼ prompt",
                                   plan.current_step_index + 1, len(plan.steps))
                    self._memory.add_message(
                        Message(role=Role.USER, content=loop_hint)
                    )
            else:
                # è¶…è¿‡å­å¾ªç¯è¿­ä»£é™åˆ¶ï¼Œå¼ºåˆ¶æ€»ç»“
                logger.warning("æ­¥éª¤ {}/{} è¾¾åˆ°æœ€å¤§è¿­ä»£æ•° {}ï¼Œå¼ºåˆ¶æ€»ç»“",
                              plan.current_step_index + 1, len(plan.steps),
                              self._step_max_iterations)
                step_result = self._force_step_answer(step, plan.goal, metrics)

            # â”€â”€ Scratchpad: å›æ»šä¸­é—´è¿‡ç¨‹ï¼Œæ²‰æ·€ç»“æœ â”€â”€
            # ä½¿ç”¨ memory åŒæ­¥è°ƒæ•´åçš„å¿«ç…§ä½ç½®ï¼ˆ_smart_truncate å¯èƒ½å·²åç§»åŸå§‹ posï¼‰
            effective_rollback_pos = self._memory.active_snapshot_pos
            if effective_rollback_pos is None:
                effective_rollback_pos = snapshot_pos
            removed = self._memory.rollback_to_snapshot(effective_rollback_pos)
            self._current_snapshot_pos = None
            if step_result is not None:
                self._memory.settle_step_result(step.description, step_result[:500])
            logger.debug("æ­¥éª¤ {} Scratchpad æ¸…ç† | ç§»é™¤ {} æ¡ä¸­é—´æ¶ˆæ¯", step.id, removed)

            return step_result

        except AgentStoppedError:
            # è¢«åœæ­¢æ—¶ä¹Ÿè¦å›æ»šï¼Œé¿å…åŠå®Œæˆçš„ä¸­é—´æ¶ˆæ¯æ±¡æŸ“åç»­
            eff_pos = self._memory.active_snapshot_pos or snapshot_pos
            self._memory.rollback_to_snapshot(eff_pos)
            self._current_snapshot_pos = None
            raise
        except Exception as e:
            # å¼‚å¸¸æ—¶å›æ»š Scratchpadï¼Œé¿å…æ±¡æŸ“
            eff_pos = self._memory.active_snapshot_pos or snapshot_pos
            self._memory.rollback_to_snapshot(eff_pos)
            self._current_snapshot_pos = None
            logger.error("æ­¥éª¤ {} æ‰§è¡Œå¼‚å¸¸: {} | messagesæ•°: {} | toolsæ•°: {}",
                         step.id, e, len(self._memory.messages),
                         len(tools_schema) if tools_schema else 0)
            return None

    def _inject_context(self, query: str, metrics: RunMetrics) -> None:
        """æ³¨å…¥çŸ¥è¯†åº“ã€é•¿æœŸè®°å¿†å’Œ Skillsï¼ˆé¦–æ­¥æ—¶è°ƒç”¨ä¸€æ¬¡ï¼‰ã€‚"""
        # çŸ¥è¯†åº“
        if self._knowledge_base and self._knowledge_base.count() > 0:
            threshold = settings.agent.kb_relevance_threshold
            results = self._knowledge_base.search(query, top_k=3, relevance_threshold=threshold)
            self._context_builder.set_knowledge(results)
            if results:
                metrics.kb_chunks_injected = len(results)
        else:
            self._context_builder.set_knowledge([])

        # é•¿æœŸè®°å¿†
        if self._vector_store and self._vector_store.count() > 0:
            threshold = settings.agent.memory_relevance_threshold
            results = self._vector_store.search(query, top_k=3)
            self._context_builder.set_memory(results, relevance_threshold=threshold)
            relevant = [r for r in results if r.get("distance", 1.0) < threshold]
            if relevant:
                metrics.memory_items_injected = len(relevant)
        else:
            self._context_builder.set_memory([])

        # Skills
        if self._skill_router:
            matches = self._skill_router.match(query)
            if matches:
                self._context_builder.set_skills([m.skill for m in matches])
            else:
                self._context_builder.set_skills([])
        else:
            self._context_builder.set_skills([])

    def _check_and_compress(self, _emit) -> None:
        """æ£€æŸ¥å¹¶æ‰§è¡Œä¸Šä¸‹æ–‡å‹ç¼©ã€‚"""
        estimate = self._context_builder.estimate_compression_needed(self._memory.messages)
        if not estimate:
            return

        _emit(AgentEvent(
            type=EventType.STATUS,
            message="ğŸ§  æ­£åœ¨æ•´ç†é•¿æœŸè®°å¿†...",
        ))
        self._memory.compress(target_tokens=estimate.target_tokens)
        _emit(AgentEvent(
            type=EventType.STATUS,
            message="âœ… è®°å¿†æ•´ç†å®Œæˆ",
        ))

    def _log_context_summary(
        self, context_messages: list, tools_schema: Optional[list],
        step_index: int, total_steps: int, iteration: int,
    ) -> None:
        """æ‰“å°æ­¥éª¤ LLM è°ƒç”¨å‰çš„ä¸Šä¸‹æ–‡æ‘˜è¦ï¼Œç”¨äºè°ƒè¯•å’Œå¯è§‚æµ‹æ€§ã€‚"""
        from collections import Counter
        role_counts = Counter()
        for msg in context_messages:
            role = msg.role.value if hasattr(msg.role, "value") else str(msg.role)
            role_counts[role] += 1

        tools_count = len(tools_schema) if tools_schema else 0
        msg_preview = []
        for i, msg in enumerate(context_messages):
            role = msg.role.value if hasattr(msg.role, "value") else str(msg.role)
            content = (msg.content or "")[:80].replace("\n", "\\n")
            msg_preview.append(f"  [{i}] {role}: {content}...")

        logger.info(
            "æ­¥éª¤ {}/{} è¿­ä»£ {} LLM è°ƒç”¨æ‘˜è¦ | messages: {} æ¡ ({}) | tools: {} ä¸ª | temp: {}",
            step_index, total_steps, iteration,
            len(context_messages),
            ", ".join(f"{r}={c}" for r, c in role_counts.items()),
            tools_count,
            self._step_temperature,
        )
        logger.debug("æ­¥éª¤ {}/{} context_messages è¯¦æƒ…:\n{}", step_index, total_steps,
                      "\n".join(msg_preview))

    def _infer_expected_tools(self, step: PlanStep) -> Optional[list]:
        """ä»æ­¥éª¤æè¿°å’Œ tool_hint æ¨æ–­é¢„æœŸå·¥å…·åˆ—è¡¨ï¼ˆç”¨äº L3 åç¦»æ£€æµ‹ï¼‰ã€‚

        åŸºäºå…³é”®è¯åŒ¹é…å°†æ­¥éª¤ç›®æ ‡æ˜ å°„åˆ°å¯èƒ½éœ€è¦çš„å·¥å…·é›†åˆã€‚
        è¿”å› None è¡¨ç¤ºæ— æ³•æ¨æ–­ï¼ˆä¸å¯ç”¨ L3 æ£€æµ‹ï¼‰ã€‚
        """
        # å¦‚æœæ­¥éª¤æœ‰æ˜ç¡®çš„ tool_hintï¼Œç›´æ¥ä½¿ç”¨
        if step.tool_hint:
            return [step.tool_hint]

        # ä»æ­¥éª¤æè¿°ä¸­å…³é”®è¯åŒ¹é…
        desc = step.description.lower()
        inferred = set()

        # å…³é”®è¯ â†’ å·¥å…·åæ˜ å°„ï¼ˆå¯æ‰©å±•ï¼‰
        keyword_tool_map = {
            ("kubernetes", "k8s", "kubectl", "é›†ç¾¤", "èŠ‚ç‚¹", "pod", "deployment",
             "daemonset", "statefulset", "namespace", "event", "äº‹ä»¶", "å·¥ä½œè´Ÿè½½"): "kubectl",
            ("docker", "å®¹å™¨", "é•œåƒ", "container", "image"): "docker",
            ("http", "api", "url", "curl", "è¯·æ±‚", "æ¥å£"): "curl",
            ("æ–‡ä»¶", "è¯»å–", "file", "read", "write", "ç›®å½•"): "file_reader",
            ("æœç´¢", "search", "æŸ¥æ‰¾", "æ£€ç´¢"): "web_search",
        }

        for keywords, tool_name in keyword_tool_map.items():
            if any(kw in desc for kw in keywords):
                inferred.add(tool_name)

        return list(inferred) if inferred else None

    def _force_step_answer(self, step: PlanStep, goal: str, metrics: RunMetrics) -> str:
        """å¼ºåˆ¶å½“å‰æ­¥éª¤ç”Ÿæˆå›ç­”ã€‚

        åœ¨è¾¾åˆ°æœ€å¤§è¿­ä»£æ•°æ—¶è°ƒç”¨ã€‚prompt ä¸­é‡æ–°æ³¨å…¥æ­¥éª¤ç›®æ ‡ï¼Œ
        é¿å… LLM åœ¨åç¦»åç”Ÿæˆæ— å…³çš„æ€»ç»“ã€‚
        """
        self._memory.add_user_message(
            f"ä½ å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚è¯·ç«‹å³åœæ­¢å·¥å…·è°ƒç”¨ï¼Œç›´æ¥ç»™å‡ºå½“å‰æ­¥éª¤çš„æ‰§è¡Œç»“æœã€‚\n\n"
            f"æé†’ - æ€»ç›®æ ‡ï¼š{goal}\n"
            f"æé†’ - å½“å‰æ­¥éª¤ï¼š{step.description}\n\n"
            f"è¯·æ ¹æ®ä»¥ä¸Šå·¥å…·è°ƒç”¨è¿”å›çš„å®é™…æ•°æ®ï¼Œæ€»ç»“å½“å‰æ­¥éª¤çš„æ‰§è¡Œç»“æœã€‚"
            f"å¦‚æœå·¥å…·æ²¡æœ‰è¿”å›æœ‰æ•ˆæ•°æ®ï¼Œè¯·å¦‚å®è¯´æ˜ã€‚"
        )
        # ä½¿ç”¨ Scratchpad å±€éƒ¨è§†å›¾ï¼Œä¸ _execute_step ä¿æŒä¸€è‡´
        # ä¼˜å…ˆä½¿ç”¨ memory åŒæ­¥è°ƒæ•´åçš„å¿«ç…§ä½ç½®
        effective_pos = self._memory.active_snapshot_pos
        if effective_pos is None:
            effective_pos = self._current_snapshot_pos
        if effective_pos is not None:
            scoped_messages = self._memory.messages_from(effective_pos)
        else:
            scoped_messages = self._memory.messages
        context_messages = self._context_builder.build(
            scoped_messages, compact_env=True,
        )
        response = self._llm.chat(
            messages=context_messages,
            tools=None,
            temperature=self._step_temperature,
            max_tokens=self._max_tokens,
        )
        metrics.record_llm_call(response.usage, call_type="force_step_answer")
        self._memory.add_assistant_message(response)
        return response.content or ""

    def _try_replan(self, plan: Plan, _emit) -> Optional[list]:
        """å°è¯•é‡æ–°è§„åˆ’å‰©ä½™æ­¥éª¤ã€‚"""
        _emit(AgentEvent(
            type=EventType.REPLAN,
            step_index=plan.current_step_index,
            total_steps=len(plan.steps),
            message=f"æ­¥éª¤å¤±è´¥ï¼Œæ­£åœ¨é‡æ–°è§„åˆ’ï¼ˆç¬¬ {plan.replan_count + 1} æ¬¡ï¼‰...",
        ))

        new_steps = replan(self._llm, plan, temperature=0.3)
        if new_steps:
            logger.info("Replan æˆåŠŸ | æ–°æ­¥éª¤æ•°: {}", len(new_steps))
            _emit(AgentEvent(
                type=EventType.PLAN_CREATED,
                plan=Plan(
                    goal=plan.goal,
                    steps=plan.completed_steps + new_steps,
                    current_step_index=len(plan.completed_steps),
                    replan_count=plan.replan_count + 1,
                ).to_dict(),
                total_steps=len(plan.completed_steps) + len(new_steps),
                message=f"å·²é‡æ–°è§„åˆ’ï¼Œå‰©ä½™ {len(new_steps)} æ­¥",
            ))
        return new_steps

    def _synthesize_answer(self, plan: Plan, metrics: RunMetrics) -> str:
        """ç»¼åˆæ‰€æœ‰æ­¥éª¤ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆå›ç­”ã€‚

        ä½¿ç”¨ Scratchpad å±€éƒ¨è§†å›¾ï¼šsynthesis_prompt å·²è‡ªåŒ…å«æ‰€æœ‰æ­¥éª¤ç»“æœï¼Œ
        ä¸éœ€è¦æºå¸¦å…¨å±€å¯¹è¯å†å²ï¼Œé¿å…æ¶ˆæ¯æ¡æ•°è¶…é™ã€‚
        """
        step_results = "\n".join(
            f"{i + 1}. {s.description}\n   ç»“æœ: {s.result_summary}"
            for i, s in enumerate(plan.steps)
            if s.status == StepStatus.COMPLETED
        )

        if not step_results:
            return "æŠ±æ­‰ï¼Œè®¡åˆ’ä¸­çš„æ‰€æœ‰æ­¥éª¤éƒ½æœªèƒ½æˆåŠŸæ‰§è¡Œã€‚"

        synthesis_prompt = _FINAL_SYNTHESIS_PROMPT.format(
            goal=plan.goal,
            step_results=step_results,
        )

        # ç»¼åˆé˜¶æ®µçš„ä¸Šä¸‹æ–‡éš”ç¦»ï¼š
        # 1. å¿«ç…§ â†’ å†™å…¥ synthesis_prompt â†’ ç”¨å±€éƒ¨è§†å›¾ build â†’ å›æ»š
        # 2. ä¸ä½¿ç”¨å·¥å…·ï¼Œæ¸…é™¤ tools é¢„ç•™
        snapshot_pos = self._memory.snapshot()
        self._memory.add_user_message(synthesis_prompt)
        self._context_builder.set_tools_reserve(None)

        scoped_messages = self._memory.messages_from(snapshot_pos)
        context_messages = self._context_builder.build(scoped_messages)
        response = self._llm.chat(
            messages=context_messages,
            tools=None,
            temperature=self._temperature,
            max_tokens=self._max_tokens,
        )
        metrics.record_llm_call(response.usage, call_type="synthesize")

        # å›æ»š synthesis çš„ä¸´æ—¶æ¶ˆæ¯ï¼Œå°†æœ€ç»ˆå›ç­”æ²‰æ·€åˆ°å…¨å±€å†å²
        self._memory.rollback_to_snapshot(snapshot_pos)
        self._memory.add_assistant_message(response)
        return response.content or "æŠ±æ­‰ï¼Œæ— æ³•ç»¼åˆæ‰§è¡Œç»“æœã€‚"

    def _fallback_direct_answer(
        self, user_input: str, metrics: RunMetrics,
        _emit, wait_for_confirmation: WaitForConfirmation = None,
    ) -> str:
        """è®¡åˆ’ç”Ÿæˆå¤±è´¥æ—¶ï¼Œå›é€€ä¸ºç›´æ¥ ReAct æ¨¡å¼ã€‚"""
        from src.agent.react_agent import ReActAgent

        logger.info("å›é€€åˆ° ReAct ç›´æ¥å›ç­”æ¨¡å¼")

        # æ„é€ ä¸´æ—¶ ReActAgentï¼Œå…±äº«æ‰€æœ‰ç»„ä»¶
        react = ReActAgent(
            llm_client=self._llm,
            tool_registry=self._tools,
            memory=self._memory,
            context_builder=self._context_builder,
            vector_store=self._vector_store,
            knowledge_base=self._knowledge_base,
            skill_router=self._skill_router,
            env_adapter=self._env_adapter,
            max_iterations=self._max_iterations,
            temperature=self._temperature,
            max_tokens=self._max_tokens,
        )

        result = react.run(user_input, on_event=_emit,
                          wait_for_confirmation=wait_for_confirmation)
        # åˆå¹¶ metricsï¼šå°† ReAct å­ agent çš„æ˜ç»†è®°å½•åˆå…¥ä¸» metrics
        if react.last_metrics:
            rm = react.last_metrics
            metrics.iterations = rm.iterations
            metrics.llm_calls.extend(rm.llm_calls)
            metrics.tool_calls.extend(rm.tool_calls)
            metrics.total_input_tokens += rm.total_input_tokens
            metrics.total_output_tokens += rm.total_output_tokens
            metrics.kb_chunks_injected = rm.kb_chunks_injected
            metrics.memory_items_injected = rm.memory_items_injected
        metrics.finish()
        self._last_metrics = metrics
        return result
