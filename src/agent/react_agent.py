"""ReAct Agent å®ç°ã€‚

æ ¸å¿ƒå¾ªç¯: ç”¨æˆ·è¾“å…¥ â†’ æ£€ç´¢çŸ¥è¯†åº“ â†’ æ£€ç´¢è®°å¿† â†’ LLM æ€è€ƒ â†’ é€‰æ‹©å·¥å…· â†’ æ‰§è¡Œ â†’ è§‚å¯Ÿç»“æœ â†’ ç»§ç»­æ€è€ƒ â†’ ... â†’ æœ€ç»ˆå›ç­” â†’ å­˜å‚¨è®°å¿†

åŸºäº OpenAI Function Calling å®ç°å·¥å…·è°ƒç”¨ï¼Œæ¯”çº¯ Prompt è§£ææ›´å¯é ã€‚

ä¸Šä¸‹æ–‡ç»„è£…é€šè¿‡ ContextBuilder å®ç° Zone åˆ†å±‚ï¼š
- System Zone: system promptï¼ˆç¨³å®šå‰ç¼€ï¼Œç¼“å­˜å‹å¥½ï¼‰
- Environment Zone: è¿è¡Œæ—¶ç¯å¢ƒä¿¡æ¯ï¼ˆå½“å‰æ—¶é—´ç­‰ï¼Œæ¯æ¬¡è¯·æ±‚åŠ¨æ€ç”Ÿæˆï¼‰
- Inject Zone: KB/é•¿æœŸè®°å¿†ï¼ˆæŒ‰éœ€ä¸´æ—¶æ³¨å…¥ï¼Œä¸æ±¡æŸ“å¯¹è¯å†å²ï¼‰
- History Zone: å¯¹è¯æ¶ˆæ¯ï¼ˆåŠ¨æ€ï¼‰

å¾ªç¯æ§åˆ¶ï¼š
- LoopDetector æ£€æµ‹é‡å¤å·¥å…·è°ƒç”¨æ¨¡å¼ï¼Œæå‰ä¸­æ–­æ— é™é‡è¯•
- æ£€æµ‹åˆ°å¾ªç¯æ—¶è‡ªåŠ¨æ’å…¥å¼•å¯¼ promptï¼Œè®© LLM æ¢ç§æ–¹å¼å›ç­”
"""

import re
import time
from typing import Any, Dict, List, Optional, TYPE_CHECKING

from src.agent.base_agent import BaseAgent, OnEventCallback, WaitForConfirmation
from src.agent.events import AgentEvent, AgentStoppedError, EventType
from src.agent.loop_detector import LoopDetector
from src.agent.metrics import RunMetrics
from src.agent.tool_executor import ToolExecutorMixin
from src.config import settings
from src.context.builder import ContextBuilder
from src.environment.adapter_base import EnvironmentAdapter
from src.llm.base_client import BaseLLMClient, Message, Role
from src.memory.conversation import ConversationMemory
from src.memory.vector_store import VectorStore
from src.observability import get_tracer
from src.observability.instruments import (
    record_agent_run_metrics, trace_span,
    set_span_content, set_span_distances,
)
from src.tools.base_tool import ToolRegistry
from src.utils.logger import logger

if TYPE_CHECKING:
    from src.rag.knowledge_base import KnowledgeBase
    from src.skills.router import SkillRouter

_tracer = get_tracer(__name__)


class ReActAgent(BaseAgent, ToolExecutorMixin):
    """ReAct (Reasoning + Acting) Agentã€‚

    é€šè¿‡ LLM çš„ Function Calling èƒ½åŠ›ï¼Œè‡ªä¸»å†³å®šä½•æ—¶è°ƒç”¨å·¥å…·ã€
    è°ƒç”¨å“ªä¸ªå·¥å…·ã€ä»¥ä»€ä¹ˆå‚æ•°è°ƒç”¨ï¼Œå¹¶æ ¹æ®å·¥å…·è¿”å›ç»“æœç»§ç»­æ¨ç†ï¼Œ
    ç›´åˆ°å¾—å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

    æ”¯æŒï¼š
    - é•¿æœŸè®°å¿†ï¼šæ¯æ¬¡å¯¹è¯å‰æ£€ç´¢ç›¸å…³è®°å¿†ï¼Œé€šè¿‡ ContextBuilder ä¸´æ—¶æ³¨å…¥
    - çŸ¥è¯†åº“é¢„æ£€ç´¢ï¼šæ¯æ¬¡å¯¹è¯å‰è‡ªåŠ¨æ£€ç´¢çŸ¥è¯†åº“ï¼Œé€šè¿‡ ContextBuilder ä¸´æ—¶æ³¨å…¥
    - å¯è§‚æµ‹æ€§ï¼šæ¯æ¬¡ run() ç”Ÿæˆ RunMetricsï¼Œè®°å½•è¿­ä»£/å·¥å…·/è€—æ—¶ç­‰æŒ‡æ ‡
    - å¾ªç¯æ§åˆ¶ï¼šLoopDetector æ£€æµ‹é‡å¤å·¥å…·è°ƒç”¨ï¼Œæå‰ä¸­æ–­æ— æ•ˆé‡è¯•
    """

    def __init__(
        self,
        llm_client: BaseLLMClient,
        tool_registry: ToolRegistry,
        memory: ConversationMemory,
        context_builder: ContextBuilder,
        vector_store: Optional[VectorStore] = None,
        knowledge_base: Optional["KnowledgeBase"] = None,
        skill_router: Optional["SkillRouter"] = None,
        env_adapter: Optional[EnvironmentAdapter] = None,
        max_iterations: Optional[int] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
    ):
        super().__init__(llm_client, tool_registry, memory)
        self._context_builder = context_builder
        self._vector_store = vector_store
        self._knowledge_base = knowledge_base
        self._skill_router = skill_router
        self._env_adapter = env_adapter
        self._max_iterations = max_iterations or settings.agent.max_iterations
        self._temperature = temperature or settings.agent.temperature
        self._max_tokens = max_tokens or settings.agent.max_tokens
        self._last_metrics: Optional[RunMetrics] = None
        self._loop_detector = LoopDetector()

    @property
    def context_builder(self) -> ContextBuilder:
        """æš´éœ² ContextBuilder å®ä¾‹ï¼Œä¾›å¤–éƒ¨è·å– build ç»Ÿè®¡ä¿¡æ¯ã€‚"""
        return self._context_builder

    @property
    def last_metrics(self) -> Optional[RunMetrics]:
        """è·å–æœ€è¿‘ä¸€æ¬¡ run() çš„è¿è¡ŒæŒ‡æ ‡ã€‚"""
        return self._last_metrics

    def run(
        self,
        user_input: str,
        on_event: OnEventCallback = None,
        wait_for_confirmation: WaitForConfirmation = None,
    ) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œæ‰§è¡Œ ReAct å¾ªç¯ç›´åˆ°å¾—åˆ°æœ€ç»ˆå›ç­”ã€‚

        å¦‚æœå¤–éƒ¨é€šè¿‡ on_event å›è°ƒæŠ›å‡º AgentStoppedErrorï¼Œ
        å°†åœ¨è¿­ä»£é—´çš„å®‰å…¨ç‚¹ä¸­æ–­ï¼Œæ‰§è¡Œæ¸…ç†åé‡æ–°æŠ›å‡ºã€‚
        """
        metrics = RunMetrics(max_iterations=self._max_iterations)
        self._loop_detector.reset()

        def _emit(event: AgentEvent) -> None:
            """å®‰å…¨åœ°å‘é€äº‹ä»¶ã€‚AgentStoppedError ä¸è¢«åæ‰ï¼Œç›´æ¥å‘ä¸Šä¼ æ’­ã€‚"""
            if on_event:
                try:
                    on_event(event)
                except AgentStoppedError:
                    raise
                except Exception as e:
                    logger.warning("äº‹ä»¶å›è°ƒå¼‚å¸¸: {}", e)

        with trace_span(_tracer, "agent.run", {"agent.max_iterations": self._max_iterations}) as span:
            set_span_content(span, "agent.input", user_input)
            try:
                result = self._run_loop(
                    user_input, metrics, _emit,
                    on_event is not None, wait_for_confirmation,
                )
                set_span_content(span, "agent.output", result)
                self._set_metrics_on_span(span, metrics)
                return result
            except AgentStoppedError:
                logger.info("ç”¨æˆ·åœæ­¢äº† Agent è¿è¡Œ | è¿­ä»£: {}", metrics.iterations)
                self._context_builder.clear_injections()
                metrics.finish()
                self._last_metrics = metrics
                logger.info("è¿è¡ŒæŒ‡æ ‡ï¼ˆç”¨æˆ·ä¸­æ–­ï¼‰ | {}", metrics.summary())
                self._set_metrics_on_span(span, metrics, stopped=True)
                raise

    @staticmethod
    def _set_metrics_on_span(span, metrics: RunMetrics, stopped: bool = False) -> None:
        """å°† RunMetrics æ‰¹é‡å†™å…¥ span attributesã€‚"""
        span.set_attribute("agent.iterations", metrics.iterations)
        span.set_attribute("agent.llm_calls", metrics.llm_call_count)
        span.set_attribute("agent.total_input_tokens", metrics.total_input_tokens)
        span.set_attribute("agent.total_output_tokens", metrics.total_output_tokens)
        span.set_attribute("agent.total_tokens", metrics.total_tokens)
        span.set_attribute("agent.tool_calls", metrics.tool_call_count)
        span.set_attribute("agent.tool_failures", metrics.tool_failure_count)
        span.set_attribute("agent.hit_max_iterations", metrics.hit_max_iterations)
        span.set_attribute("agent.loop_detected", metrics.loop_detected)
        span.set_attribute("agent.duration_ms", round(metrics.duration_ms, 1))
        span.set_attribute("agent.stopped", stopped)
        if metrics.kb_chunks_injected:
            span.set_attribute("agent.kb_chunks_injected", metrics.kb_chunks_injected)
        if metrics.memory_items_injected:
            span.set_attribute("agent.memory_items_injected", metrics.memory_items_injected)

        # è®°å½• agent run metrics
        record_agent_run_metrics(
            duration_ms=metrics.duration_ms,
            hit_max_iterations=metrics.hit_max_iterations,
        )

    def _run_loop(
        self, user_input: str, metrics: RunMetrics, _emit,
        has_callback: bool, wait_for_confirmation: WaitForConfirmation = None,
    ) -> str:
        """ReAct æ ¸å¿ƒå¾ªç¯ï¼Œä» run() ä¸­åˆ†ç¦»ä»¥ä¾¿ç»Ÿä¸€å¼‚å¸¸å¤„ç†ã€‚"""
        # 1. æ£€ç´¢çŸ¥è¯†åº“ï¼Œé€šè¿‡ ContextBuilder ä¸´æ—¶æ³¨å…¥ï¼ˆä¸å†™å…¥ ConversationMemoryï¼‰
        self._inject_knowledge(user_input, metrics)
        # 2. æ£€ç´¢é•¿æœŸè®°å¿†ï¼Œé€šè¿‡ ContextBuilder ä¸´æ—¶æ³¨å…¥
        self._inject_long_term_memory(user_input, metrics)
        # 3. åŒ¹é…å¹¶æ³¨å…¥ Skillsï¼ˆé¢†åŸŸä¸“å®¶ promptï¼‰
        self._inject_skills(user_input)

        # 4. ç”¨æˆ·æ¶ˆæ¯å†™å…¥å¯¹è¯å†å²ï¼ˆè¿™æ˜¯çœŸæ­£åº”è¯¥æŒä¹…åŒ–çš„ï¼‰
        self._memory.add_user_message(user_input)

        # 5. æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼© History Zoneï¼ˆåŒæ­¥é˜»å¡ï¼‰
        self._check_and_compress(_emit)

        tools_schema = self._tools.to_openai_tools() if len(self._tools) > 0 else None

        # å°† tools schema çš„ token å ç”¨çº³å…¥ä¸Šä¸‹æ–‡é¢„ç®—ï¼Œé¿å… messages + tools è¶…é™
        self._context_builder.set_tools_reserve(tools_schema)

        for iteration in range(1, self._max_iterations + 1):
            metrics.iterations = iteration
            logger.info("ReAct è¿­ä»£ [{}/{}]", iteration, self._max_iterations)

            _emit(AgentEvent(
                type=EventType.THINKING,
                iteration=iteration,
                max_iterations=self._max_iterations,
            ))

            # é€šè¿‡ ContextBuilder ç»„è£…å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆSystem + Inject + Historyï¼‰
            context_messages = self._context_builder.build(self._memory.messages)

            # è°ƒç”¨ LLM
            response = self._llm.chat(
                messages=context_messages,
                tools=tools_schema,
                temperature=self._temperature,
                max_tokens=self._max_tokens,
            )
            metrics.record_llm_call(response.usage, call_type="chat")

            # æƒ…å†µ1: LLM ç›´æ¥ç»™å‡ºæœ€ç»ˆå›ç­”ï¼ˆæ²¡æœ‰ tool_callsï¼‰
            if not response.tool_calls:
                self._memory.add_assistant_message(response)
                logger.info("Agent ç»™å‡ºæœ€ç»ˆå›ç­”")

                _emit(AgentEvent(
                    type=EventType.ANSWERING,
                    iteration=iteration,
                    max_iterations=self._max_iterations,
                ))

                self._store_to_long_term_memory(user_input, response.content or "", metrics)
                self._context_builder.clear_injections()
                metrics.finish()
                self._last_metrics = metrics
                logger.info("è¿è¡ŒæŒ‡æ ‡ | {}", metrics.summary())
                return response.content or ""

            # æƒ…å†µ2: LLM å†³å®šè°ƒç”¨å·¥å…·
            self._memory.add_assistant_message(response)
            self.execute_tool_calls(response.tool_calls, metrics, _emit, wait_for_confirmation)

            # å¾ªç¯æ£€æµ‹ï¼šå¦‚æœæ£€æµ‹åˆ°é‡å¤è°ƒç”¨æ¨¡å¼ï¼Œæ’å…¥å¼•å¯¼ prompt
            loop_hint = self._loop_detector.get_loop_summary()
            if loop_hint:
                metrics.loop_detected = True
                logger.warning("å¾ªç¯æ£€æµ‹è§¦å‘ï¼Œæ’å…¥å¼•å¯¼ prompt")
                self._memory.add_message(
                    Message(role=Role.USER, content=loop_hint)
                )

        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼ºåˆ¶è®© LLM æ€»ç»“
        metrics.hit_max_iterations = True
        logger.warning("è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {}ï¼Œå¼ºåˆ¶æ€»ç»“", self._max_iterations)

        _emit(AgentEvent(
            type=EventType.MAX_ITERATIONS,
            iteration=self._max_iterations,
            max_iterations=self._max_iterations,
        ))

        answer = self._force_final_answer(metrics)
        self._store_to_long_term_memory(user_input, answer, metrics)
        self._context_builder.clear_injections()
        metrics.finish()
        self._last_metrics = metrics
        logger.info("è¿è¡ŒæŒ‡æ ‡ | {}", metrics.summary())
        return answer

    def _inject_knowledge(self, query: str, metrics: RunMetrics) -> None:
        """æ£€ç´¢çŸ¥è¯†åº“ï¼Œé€šè¿‡ ContextBuilder ä¸´æ—¶æ³¨å…¥ä¸Šä¸‹æ–‡ã€‚

        ä»…å½“æ£€ç´¢ç»“æœä¸ query çš„ cosine distance ä½äºé˜ˆå€¼æ—¶æ‰æ³¨å…¥ï¼Œ
        é¿å…ä¸ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µæµªè´¹ tokenã€‚
        æ£€ç´¢ distance åˆ†æ•°è®°å½•åˆ°å½“å‰ Spanï¼Œä¾¿äºå¯è§‚æµ‹å’Œé˜ˆå€¼è°ƒä¼˜ã€‚
        """
        if not self._knowledge_base or self._knowledge_base.count() == 0:
            self._context_builder.set_knowledge([])
            return

        with trace_span(_tracer, "rag.knowledge_search", {"rag.type": "knowledge_base"}) as span:
            threshold = settings.agent.kb_relevance_threshold
            results = self._knowledge_base.search(query, top_k=3, relevance_threshold=threshold)
            self._context_builder.set_knowledge(results)

            # è®°å½•æ£€ç´¢ distance åˆ° Spanï¼ˆå«è¢«è¿‡æ»¤æ‰çš„å€™é€‰ï¼Œç”¨äºé˜ˆå€¼è°ƒä¼˜ï¼‰
            all_candidates = self._knowledge_base.search(query, top_k=3, relevance_threshold=2.0)
            set_span_distances(
                "kb.distances", all_candidates, threshold, injected_count=len(results),
            )

            span.set_attribute("rag.threshold", threshold)
            span.set_attribute("rag.candidates", len(all_candidates))
            span.set_attribute("rag.injected", len(results))

            if results:
                metrics.kb_chunks_injected = len(results)
                logger.info("æ³¨å…¥ {} æ¡çŸ¥è¯†åº“ç‰‡æ®µï¼ˆthreshold={}ï¼‰", len(results), threshold)

    def _inject_long_term_memory(self, query: str, metrics: RunMetrics) -> None:
        """æ£€ç´¢é•¿æœŸè®°å¿†ï¼Œé€šè¿‡ ContextBuilder ä¸´æ—¶æ³¨å…¥ä¸Šä¸‹æ–‡ã€‚

        ä»…å½“æ£€ç´¢ç»“æœä¸ query çš„ cosine distance ä½äºé˜ˆå€¼æ—¶æ‰æ³¨å…¥ï¼Œ
        é¿å…ä¸ç›¸å…³çš„è®°å¿†æµªè´¹ tokenã€‚
        æ£€ç´¢ distance åˆ†æ•°è®°å½•åˆ°å½“å‰ Spanï¼Œä¾¿äºå¯è§‚æµ‹å’Œé˜ˆå€¼è°ƒä¼˜ã€‚

        å‘½ä¸­çš„è®°å¿†ä¼šå¼‚æ­¥æ›´æ–° hit_count å’Œ last_hitï¼ˆä¾› Governor è¯„ä¼°ä»·å€¼ï¼‰ã€‚
        """
        if not self._vector_store or self._vector_store.count() == 0:
            self._context_builder.set_memory([])
            return

        with trace_span(_tracer, "rag.memory_search", {"rag.type": "long_term_memory"}) as span:
            threshold = settings.agent.memory_relevance_threshold
            results = self._vector_store.search(query, top_k=3)
            self._context_builder.set_memory(results, relevance_threshold=threshold)

            # è®°å½•æ£€ç´¢ distance åˆ° Spanï¼ˆå…¨éƒ¨å€™é€‰ï¼Œå«è¢«è¿‡æ»¤çš„ï¼‰
            set_span_distances(
                "memory.distances", results, threshold,
                injected_count=len([r for r in results if r.get("distance", 1.0) < threshold]),
            )

            relevant = [r for r in results if r.get("distance", 1.0) < threshold]
            span.set_attribute("rag.threshold", threshold)
            span.set_attribute("rag.candidates", len(results))
            span.set_attribute("rag.injected", len(relevant))

            if relevant:
                metrics.memory_items_injected = len(relevant)
                logger.info("æ³¨å…¥ {} æ¡é•¿æœŸè®°å¿†ï¼ˆthreshold={}ï¼‰", len(relevant), threshold)

                # å¼‚æ­¥ hit writebackï¼šæ›´æ–°å‘½ä¸­è®°å¿†çš„ hit_count å’Œ last_hit
                if settings.agent.memory_governor_enabled:
                    self._writeback_memory_hits(relevant)

    def _writeback_memory_hits(self, relevant_memories: List[Dict[str, Any]]) -> None:
        """å¼‚æ­¥æ›´æ–°å‘½ä¸­è®°å¿†çš„ hit_count å’Œ last_hitã€‚

        ä½¿ç”¨åå°çº¿ç¨‹æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»è¯·æ±‚é“¾è·¯ã€‚
        """
        if not self._vector_store:
            return

        import threading
        store = self._vector_store

        def _do_writeback():
            now = time.time()
            for mem in relevant_memories:
                mem_id = mem.get("id")
                if not mem_id:
                    continue
                meta = mem.get("metadata", {})
                store.update_metadata(mem_id, {
                    "hit_count": meta.get("hit_count", 0) + 1,
                    "last_hit": now,
                })

        threading.Thread(
            target=_do_writeback,
            name="memory-hit-writeback",
            daemon=True,
        ).start()

    def _inject_skills(self, user_input: str) -> None:
        """æ ¹æ®ç”¨æˆ·æ„å›¾åŒ¹é… Skillsï¼Œé€šè¿‡ ContextBuilder ä¸´æ—¶æ³¨å…¥é¢†åŸŸä¸“å®¶ promptã€‚

        Skills åœ¨æ¯æ¬¡å¯¹è¯å¼€å§‹æ—¶åŒ¹é…ä¸€æ¬¡ï¼Œæ³¨å…¥ååœ¨æ•´ä¸ª ReAct å¾ªç¯ä¸­æŒç»­ç”Ÿæ•ˆã€‚
        """
        if not self._skill_router:
            self._context_builder.set_skills([])
            return

        matches = self._skill_router.match(user_input)
        if matches:
            skills = [m.skill for m in matches]
            self._context_builder.set_skills(skills)
            skill_names = [f"{m.skill.display_name}({m.score:.2f})" for m in matches]
            logger.info("æ¿€æ´» Skills: {}", ", ".join(skill_names))
        else:
            self._context_builder.set_skills([])

    def _check_and_compress(self, _emit) -> None:
        """æ£€æŸ¥ History Zone æ˜¯å¦è¶…è¿‡æ°´ä½çº¿ï¼Œéœ€è¦æ—¶åŒæ­¥è§¦å‘å‹ç¼©ã€‚

        åœ¨ ReAct å¾ªç¯å¼€å§‹å‰è°ƒç”¨ã€‚ä½¿ç”¨ ContextBuilder.estimate_compression_needed()
        ä¼°ç®—åŠ¨æ€é¢„ç®—ï¼Œè¶…è¿‡é˜ˆå€¼æ—¶è°ƒç”¨ ConversationMemory.compress() åŒæ­¥å‹ç¼©ã€‚

        å‹ç¼©è¿‡ç¨‹é€šè¿‡ STATUS äº‹ä»¶é€šçŸ¥å‰ç«¯å±•ç¤ºè¿›åº¦ã€‚
        å¦‚æœå‹ç¼©å¤±è´¥ï¼ŒæŠ›å‡º CompressionErrorï¼Œç”±ä¸Šå±‚ AgentService æ•è·è¿”å›ç”¨æˆ·é”™è¯¯ã€‚
        """
        estimate = self._context_builder.estimate_compression_needed(self._memory.messages)
        if not estimate:
            return

        logger.info(
            "History Zone è¶…è¿‡æ°´ä½çº¿ | history={} tokens, budget={} tokens, é˜ˆå€¼={}",
            estimate.history_tokens, estimate.history_budget,
            settings.agent.compression_threshold,
        )

        _emit(AgentEvent(
            type=EventType.STATUS,
            message="ğŸ§  æ­£åœ¨æ•´ç†é•¿æœŸè®°å¿†...",
        ))

        # åŒæ­¥é˜»å¡æ‰§è¡Œå‹ç¼©ï¼ˆCompressionError ä¼šè‡ªç„¶å‘ä¸Šä¼ æ’­ï¼‰
        self._memory.compress(target_tokens=estimate.target_tokens)

        _emit(AgentEvent(
            type=EventType.STATUS,
            message="âœ… è®°å¿†æ•´ç†å®Œæˆ",
        ))

    def _store_to_long_term_memory(self, user_input: str, answer: str,
                                   metrics: Optional[RunMetrics] = None) -> None:
        """å°†å¯¹è¯ä¸­çš„å…³é”®äº‹å®æå–å¹¶å­˜å‚¨åˆ°é•¿æœŸè®°å¿†ã€‚

        ä½¿ç”¨ LLM ä» Q&A ä¸­æå–å€¼å¾—è®°ä½çš„å…³é”®äº‹å®ï¼ˆåå¥½ã€ç»“è®ºã€æ•°æ®ï¼‰ï¼Œ
        è€Œéå­˜å‚¨åŸå§‹çš„"ç”¨æˆ·é—®/å›ç­”"æ‹¼æ¥ï¼Œæé«˜è®°å¿†è´¨é‡å’Œæ£€ç´¢ç²¾åº¦ã€‚
        """
        if not self._vector_store:
            return

        if len(user_input.strip()) < 5 or len(answer.strip()) < 10:
            return

        # å°è¯•ç”¨ LLM æå–å…³é”®äº‹å®
        key_facts = self._extract_key_facts(user_input, answer, metrics)
        if key_facts:
            self._vector_store.add(
                text=key_facts,
                metadata={"type": "key_facts", "question": user_input[:200]},
            )
            logger.debug("ç»“æ„åŒ–è®°å¿†å·²å­˜å…¥é•¿æœŸè®°å¿†: {}", key_facts[:100])
        else:
            # LLM æå–å¤±è´¥æ—¶å›é€€åˆ°ç®€å•å­˜å‚¨ï¼Œæ¸…æ´—æ ¼å¼è£…é¥°ä»¥å‡å°‘å™ªå£°
            clean_answer = _clean_text_for_memory(answer[:300])
            summary = f"ç”¨æˆ·é—®: {user_input[:200]} | å›ç­”: {clean_answer}"
            self._vector_store.add(
                text=summary,
                metadata={"type": "conversation", "question": user_input[:200]},
            )
            logger.debug("å¯¹è¯å·²å­˜å…¥é•¿æœŸè®°å¿†ï¼ˆå›é€€æ¨¡å¼ï¼‰")

    def _extract_key_facts(self, user_input: str, answer: str,
                           metrics: Optional[RunMetrics] = None) -> Optional[str]:
        """ä½¿ç”¨ LLM ä»å¯¹è¯ä¸­æå–å€¼å¾—é•¿æœŸè®°ä½çš„å…³é”®äº‹å®ã€‚

        Returns:
            æå–çš„å…³é”®äº‹å®æ–‡æœ¬ï¼›å¦‚æœå¯¹è¯ä¸å€¼å¾—è®°å¿†æˆ–æå–å¤±è´¥ï¼Œè¿”å› Noneã€‚
        """
        try:
            extract_prompt = [
                Message(
                    role=Role.SYSTEM,
                    content=(
                        "ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–å€¼å¾—é•¿æœŸè®°ä½çš„å…³é”®äº‹å®ã€‚\n\n"
                        "æå–è§„åˆ™ï¼š\n"
                        "1. åªæå–å®¢è§‚äº‹å®ã€ç”¨æˆ·åå¥½ã€æ˜ç¡®ç»“è®ºã€é‡è¦æ•°æ®\n"
                        "2. è·³è¿‡å¯’æš„ã€é—²èŠã€é‡å¤çš„å¸¸è¯†æ€§é—®ç­”\n"
                        "3. ç”¨ç®€æ´çš„çº¯æ–‡æœ¬é™ˆè¿°å¥è¾“å‡ºï¼Œæ¯æ¡äº‹å®ä¸€è¡Œï¼Œæœ€å¤š 3 æ¡\n"
                        "4. ä¸è¦ä½¿ç”¨ Markdown æ ¼å¼ã€è¡¨æƒ…ç¬¦å·æˆ–è£…é¥°æ€§ç¬¦å·\n"
                        '5. å¦‚æœå¯¹è¯æ²¡æœ‰å€¼å¾—è®°å¿†çš„å…³é”®äº‹å®ï¼Œåªè¾“å‡º"æ— "\n\n'
                        "ç¤ºä¾‹è¾“å‡ºï¼š\n"
                        "ç”¨æˆ·åå¥½ä½¿ç”¨ Python è¿›è¡Œæ•°æ®åˆ†æ\n"
                        "é¡¹ç›®éƒ¨ç½²åœ¨ 3 ä¸ª Kubernetes namespace ä¸­"
                    ),
                ),
                Message(
                    role=Role.USER,
                    content=f"ç”¨æˆ·: {user_input[:300]}\nåŠ©æ‰‹: {answer[:500]}",
                ),
            ]

            response = self._llm.chat(
                messages=extract_prompt,
                temperature=0.1,
                max_tokens=200,
            )
            if metrics:
                metrics.record_llm_call(response.usage, call_type="extract_facts")

            result = (response.content or "").strip()
            # å¦‚æœ LLM åˆ¤æ–­ä¸å€¼å¾—è®°å¿†
            if not result or result == "æ— ":
                logger.debug("LLM åˆ¤æ–­å¯¹è¯ä¸å«å€¼å¾—è®°å¿†çš„å…³é”®äº‹å®")
                return None
            return result
        except Exception as e:
            logger.warning("å…³é”®äº‹å®æå–å¤±è´¥: {}", e)
            return None

    def _force_final_answer(self, metrics: Optional[RunMetrics] = None) -> str:
        """å¼ºåˆ¶ LLM åŸºäºå½“å‰ä¸Šä¸‹æ–‡ç»™å‡ºæœ€ç»ˆå›ç­”ï¼ˆä¸å†è°ƒç”¨å·¥å…·ï¼‰ã€‚"""
        self._memory.add_user_message(
            "è¯·æ ¹æ®ä»¥ä¸Šæ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœï¼Œç›´æ¥ç»™å‡ºæœ€ç»ˆçš„å®Œæ•´å›ç­”ï¼Œä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ã€‚"
        )
        context_messages = self._context_builder.build(self._memory.messages)
        response = self._llm.chat(
            messages=context_messages,
            tools=None,
            temperature=self._temperature,
            max_tokens=self._max_tokens,
        )
        if metrics:
            metrics.record_llm_call(response.usage, call_type="force_answer")
        self._memory.add_assistant_message(response)
        return response.content or "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¾—å‡ºç»“è®ºã€‚"


# Emoji Unicode èŒƒå›´æ­£åˆ™
_EMOJI_PATTERN = re.compile(
    "[\U0001F300-\U0001F9FF"   # å„ç±»è¡¨æƒ…ç¬¦å·
    "\U00002702-\U000027B0"    # æ‚é¡¹ç¬¦å·
    "\U0000FE00-\U0000FE0F"    # å˜ä½“é€‰æ‹©ç¬¦
    "\U0000200D"               # é›¶å®½è¿æ¥ç¬¦
    "]+",
    flags=re.UNICODE,
)

# Markdown æ ¼å¼æ ‡è®°æ­£åˆ™
_MARKDOWN_PATTERN = re.compile(
    r"#{1,6}\s+"               # æ ‡é¢˜ ## xxx
    r"|(?<!\S)\*{1,3}|"       # åŠ ç²—/æ–œä½“ **xxx** *xxx*
    r"\*{1,3}(?!\S)"
    r"|(?<!\S)_{1,2}|"        # ä¸‹åˆ’çº¿å¼ºè°ƒ __xxx__
    r"_{1,2}(?!\S)"
    r"|^[-*+]\s+"              # åˆ—è¡¨é¡¹ - xxx / * xxx
    r"|^\d+\.\s+",             # æœ‰åºåˆ—è¡¨ 1. xxx
    flags=re.MULTILINE,
)


def _clean_text_for_memory(text: str) -> str:
    """æ¸…æ´—æ–‡æœ¬ä¸­çš„æ ¼å¼è£…é¥°ï¼Œç”¨äºè®°å¿†å­˜å‚¨ã€‚

    ç§»é™¤ emojiã€Markdown æ ‡è®°ï¼Œå‹ç¼©å¤šä½™ç©ºç™½ï¼Œ
    ä½¿å­˜å…¥å‘é‡åº“çš„æ–‡æœ¬å¹²å‡€ã€åˆ©äº embedding è¯­ä¹‰åŒ¹é…ã€‚
    """
    text = _EMOJI_PATTERN.sub("", text)
    text = _MARKDOWN_PATTERN.sub("", text)
    # å‹ç¼©è¿ç»­ç©ºè¡Œå’Œç©ºç™½
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = re.sub(r" {2,}", " ", text)
    return text.strip()
